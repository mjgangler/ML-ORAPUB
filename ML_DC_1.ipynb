{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6205e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Machine Learning Data Collector\")\n",
    "\n",
    "lastUpdate = \"17-Apr-2021\"\n",
    "print(\"Last update:\", lastUpdate)\n",
    "\n",
    "TESTING     = False\n",
    "IN_NOTEBOOK = True\n",
    "CMD_CHECK   = '' # Only used if InNotebook, then normally, set to '' or to do a check, set to either 'db' or 'email'\n",
    "\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796c9a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading core Python libraries\", end=\"...\")\n",
    "\n",
    "import numpy  as np # for number crunching\n",
    "import pandas as pd # for dataframe manipulation and preprocessing\n",
    "import os\n",
    "from collections import Counter\n",
    "import cx_Oracle # notice the uppercase O in Oracle... different from the package name\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad96ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key Settings\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#PARE_CORE = \"\"\n",
    "\n",
    "BASE_DIR    = os.getcwd() + \"/\"\n",
    "\n",
    "CHARTS_DIR_2D = BASE_DIR + \"charts2D\"   # <-------- Make sure this directory exists!!!\n",
    "CHARTS_DIR_3D = BASE_DIR + \"charts3D\"   # <-------- Make sure this directory exists!!!\n",
    "ALERT_FN      = BASE_DIR + \"ml_dc_alertlog.txt\"  # Not really used at the moment\n",
    "CONFIG_FILE   = BASE_DIR + \"ML_DC.cfg\"\n",
    "\n",
    "print()\n",
    "print(\"Directories and files:\")\n",
    "print(\"  BASE_DIR     \", BASE_DIR)\n",
    "print(\"  CHARTS_DIR_2D\", CHARTS_DIR_2D)\n",
    "print(\"  CHARTS_DIR_3D\", CHARTS_DIR_3D)\n",
    "print(\"  CONFIG_FILE  \", CONFIG_FILE)\n",
    "print(\"  ALERT_FN     \", ALERT_FN)\n",
    "\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e676b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TESTING:\n",
    "    G_current_seq_num = 0\n",
    "    G_sysmetric_last_beg_time = datetime.now() - timedelta(days=1)\n",
    "    G_sysmetric_last_end_time = datetime.now() - timedelta(days=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d70ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doExit():\n",
    "    import sys\n",
    "    print('Exiting clean')\n",
    "    try:    \n",
    "        cursor.close()\n",
    "        dbConnection.close()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    sys.exit() \n",
    "    \n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c56efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2bool(v):\n",
    "    return v.lower() in (\"yes\", \"true\", \"t\", \"1\")\n",
    "\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840731a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alertLogWrite(line_in):\n",
    "\n",
    "    from datetime import datetime\n",
    "\n",
    "    now = datetime.now().strftime(\"%d-%b-%Y %H:%M:%S\")\n",
    "\n",
    "    f = open(ALERT_FN,\"a\")\n",
    "    f.write(now + \", \" + line_in + \"\\n\")\n",
    "    \n",
    "if TESTING:\n",
    "    x = \"Yo Craig, This is an alert log test.\"\n",
    "    alertLogWrite(x)\n",
    "\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca4b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkDBFileChange():\n",
    "\n",
    "    # Check if DB access credentials have changed in the ML-DC-DB.py file.\n",
    "    \n",
    "    change = False\n",
    "    \n",
    "    import ML_DC_DB as db\n",
    "    import importlib\n",
    "    \n",
    "    current_user = db.user\n",
    "    current_pw   = db.pw\n",
    "    current_dsn  = db.dsn\n",
    "    \n",
    "    importlib.reload(db)\n",
    "    \n",
    "    if (current_user != db.user or current_pw != db.pw or current_dsn != db.dsn):\n",
    "        change = True\n",
    "    else:\n",
    "        change = False\n",
    "    \n",
    "    return(change)\n",
    "\n",
    "if TESTING:\n",
    "    print('Testing Function: checkDBFileChange')\n",
    "    print(checkDBFileChange())\n",
    "\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09d18c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readParamFile(verbose_in):\n",
    "    \n",
    "    # ref: https://zetcode.com/python/configparser\n",
    "    \n",
    "    import configparser\n",
    "    \n",
    "    config = configparser.ConfigParser()\n",
    "    \n",
    "    fullConfigFile = CONFIG_FILE\n",
    "    config.read(fullConfigFile)\n",
    "    \n",
    "    try:\n",
    "        prior = G_par_core\n",
    "    except:\n",
    "        prior = config['core']\n",
    "    \n",
    "    myParCore = config['core']\n",
    "    \n",
    "    pars = str({section: dict(config[section]) for section in config.sections()})\n",
    "    \n",
    "    if verbose_in:\n",
    "        print('\\nParameter Settings:\\n')\n",
    "        print(pars, '\\n')\n",
    "        alertLogWrite('Current Parameters, ' + pars)\n",
    "    \n",
    "    if prior != myParCore:\n",
    "        alertLogWrite('Detected parameter file change, ' + pars)\n",
    "        print('\\nParemeter Setting CHANGE:\\n')\n",
    "        print(pars, '\\n')\n",
    "    \n",
    "    return(myParCore)\n",
    "\n",
    "if TESTING:\n",
    "    print('Testing Function: readParamFile')\n",
    "    # pareCore is outside of the function, so results available everywhere\n",
    "    G_par_core = readParamFile(True) # keep result as parCore, so it can be used when testing\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c6fdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closeDbConnection(verbose_in):\n",
    "    \n",
    "    import cx_Oracle\n",
    "    \n",
    "    if verbose_in:\n",
    "        print(\"Closing DB connection\", end=\"...\")\n",
    "    try:\n",
    "        cursor.close()\n",
    "        dbConnection.close()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if verbose_in:\n",
    "        print(\"completed.\")\n",
    "\n",
    "if TESTING:\n",
    "    closeDbConnection(True)\n",
    "\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c68af19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openDbConnection(show_error_in, verbose_in):\n",
    "    \n",
    "    import ML_DC_DB as db\n",
    "    import cx_Oracle\n",
    "    import os\n",
    "    import importlib\n",
    "    \n",
    "    \n",
    "    importlib.reload(db)\n",
    "    \n",
    "    conTF = False\n",
    "    \n",
    "    if verbose_in:\n",
    "        print('Attempting Oracle connection db.user db.dsn ', db.user, db.dsn, end=' ...')\n",
    "    \n",
    "    try:\n",
    "        closeDbConnection(verbose_in)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        conDetails = cx_Oracle.connect(db.user, db.pw, db.dsn)\n",
    "    \n",
    "    except cx_Oracle.Error as e:\n",
    "        conDetails = 0\n",
    "        \n",
    "        if show_error_in:            \n",
    "            errorObj, = e.args\n",
    "            print('failed to connect.')\n",
    "            print('   Error Code       :', errorObj.code)\n",
    "            print('   Error Message    :', errorObj.message)\n",
    "            print('   TNS_ADMIN        :', os.getenv('TNS_ADMIN'))\n",
    "            print('   PATH             :', os.getenv('PATH'))\n",
    "            print('   DYLD_LIBRARY_PATH:', os.getenv('DYLD_LIBRARY_PATH'))\n",
    "    \n",
    "    else:\n",
    "        conTF = True\n",
    "        if verbose_in:\n",
    "            print('Connection success.')\n",
    "            print('Connected Oracle version', conDetails.version)\n",
    "        \n",
    "    return( conTF, conDetails )\n",
    "\n",
    "\n",
    "if TESTING:\n",
    "    print('Testing Function: makeDbConnection \\n')\n",
    "    \n",
    "    print('Test 1')\n",
    "    result, conQ = openDbConnection(show_error_in=True,verbose_in=True)\n",
    "    print('Test 1 result', result, 'dbConnection', conQ)\n",
    "    \n",
    "    print('\\nTest 2')\n",
    "    result, conQ = openDbConnection(show_error_in=True,verbose_in=False)\n",
    "    print('Test 2 result', result, 'dbConnection', conQ)\n",
    " \n",
    "    print('\\nDone.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a79dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runSQL(sql_in, verbose_in):\n",
    "    \n",
    "    if verbose_in:\n",
    "        print(\"\\nENTER Function runSQL\")\n",
    "    \n",
    "    myResult = False\n",
    "    \n",
    "    DF = pd.DataFrame()\n",
    "    \n",
    "    if verbose_in:\n",
    "        print(\"sql:\", sql_in)\n",
    "    \n",
    "    try:\n",
    "        result, myDbConnection = openDbConnection(show_error_in=True, verbose_in=verbose_in)\n",
    "        \n",
    "        DF = pd.read_sql(sql_in, con=myDbConnection)\n",
    "        \n",
    "        if verbose_in:\n",
    "            print(\"Result test shape\", DF.shape)\n",
    "        \n",
    "        myResult = True\n",
    "    \n",
    "    except:\n",
    "        print(\"Error, runSQL, failed:\", sql_in)\n",
    "    \n",
    "    try:\n",
    "        closeDbConnection(verbose_in)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if verbose_in:\n",
    "        print(\"\\nEXIT Function runSQL\")\n",
    "        \n",
    "    return myResult, DF\n",
    "\n",
    "if TESTING:\n",
    "    qTF, qDF = runSQL(\"select * from dual\", True)\n",
    "    print(qTF)\n",
    "    print(qDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecf8ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def querySourceCheck(object_in, verbose_in):\n",
    "            \n",
    "    import cx_Oracle\n",
    "    \n",
    "    myResult = False\n",
    "    \n",
    "    if verbose_in:\n",
    "        print('Attempting to query from', object_in)\n",
    "    \n",
    "    parObjectName  = object_in + \"_object_name\"\n",
    "    parWhereClause = object_in + \"_where_clause\"\n",
    "    \n",
    "    sql = \"select count(*) from \" + G_par_core[parObjectName] \\\n",
    "    + \" where \" + G_par_core[parWhereClause] + \" and rownum < 5\"\n",
    "    \n",
    "    myResult, DF = runSQL(sql, verbose_in)\n",
    "    \n",
    "    return(myResult, DF)\n",
    "\n",
    "\n",
    "if TESTING:\n",
    "    print('Testing Function: querySourceCheck')\n",
    "    \n",
    "    print(\"\\nTest 1 ASH verbose:True\")\n",
    "    qTF, qDF = querySourceCheck(\"ash\", True)\n",
    "    print(\"Test Result\", qTF, qDF.shape)\n",
    "    \n",
    "    print(\"\\nTest 2 SYSMETRIC verbose:False\")\n",
    "    qTF, qDF = querySourceCheck(\"sysmetric\", False)\n",
    "    print(\"Test Result\", qTF, qDF.shape)\n",
    "    \n",
    "    print(\"\\nTest 3 LABEL verbose:False\")\n",
    "    qTF, qDF = querySourceCheck(\"label\", False)\n",
    "    print(\"Test Result\", qTF, qDF.shape)\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60868d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IsNewDataAvailable(verbose_in):\n",
    "    \n",
    "    # Note: Using a SYSMETRIC end_time increase to indicate new data is available.\n",
    "    \n",
    "    if verbose_in:\n",
    "        print(\"\\nENTER Function IsNewDataAvailable\")\n",
    "    \n",
    "    NewData = False\n",
    "    begDate = datetime.today() - timedelta(days=100) # just to get a valid date type\n",
    "    endDate = datetime.today() - timedelta(days=100) # just to get a valid date type\n",
    "    \n",
    "    sql = \"select min(begin_time) BT, max(end_time) ET from \" + G_par_core[\"sysmetric_object_name\"] \\\n",
    "    + \" where \" + G_par_core[\"sysmetric_where_clause\"]\n",
    "    \n",
    "    runSQLTF, DF = runSQL(sql, verbose_in)\n",
    "    \n",
    "    if runSQLTF:\n",
    "        if DF.ET[0] > G_sysmetric_last_end_time:\n",
    "            NewData = True\n",
    "            endDate = DF.ET[0]\n",
    "            begDate = DF.BT[0]\n",
    "    \n",
    "    if verbose_in:\n",
    "        print(\"\\nEXIT Function IsNewDataAvailable\")\n",
    "    \n",
    "    return NewData, begDate, endDate\n",
    "\n",
    "if TESTING:\n",
    "    qTF, qBegDate, qEndDate = IsNewDataAvailable(True)\n",
    "    if qTF:\n",
    "        G_sysmetric_last_beg_time = qBegDate\n",
    "        G_sysmetric_last_end_time = qEndDate\n",
    "    print(\"1\", qTF, qBegDate, qEndDate)\n",
    "    print(\"2     \", G_sysmetric_last_beg_time, G_sysmetric_last_end_time)\n",
    "    #print(\"3     \", G_sysmetric_last_beg_time.strftime(\"%d-%b-%Y %H:%M:%S\"), G_sysmetric_last_end_time.strftime(\"%d-%b-%Y %H:%M:%S\"))\n",
    "    \n",
    "    #print(\"\\nSleeping 2s...\\n\")\n",
    "    #time.sleep(2)\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996c0472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSysmetricData(sysmetric_last_end_time_in, verbose_in):\n",
    "    \n",
    "    if verbose_in:\n",
    "        print(\"\\nENTER Function getSysmetricData\")\n",
    "    \n",
    "    sysmetric_last_end_time = sysmetric_last_end_time_in.strftime(\"%d-%b-%Y %H:%M:%S\")\n",
    "    \n",
    "    sql = \"select begin_time sample_time_beg, end_time sample_time_end, metric_name, value metric_value from \" \\\n",
    "    + G_par_core[\"sysmetric_object_name\"] \\\n",
    "    + \" where \" + G_par_core[\"sysmetric_where_clause\"] \\\n",
    "    + \"   and end_time > to_date('\" + sysmetric_last_end_time + \"','DD-Mon-YYYY HH24:MI:SS')\" \\\n",
    "    + \" order by 1, 2\"\n",
    "    \n",
    "    runSQLTF, DF = runSQL(sql, verbose_in)\n",
    "    \n",
    "    if verbose_in:\n",
    "        print(\"\\nEXIT Function getSysmetricData\")\n",
    "    \n",
    "    return runSQLTF, DF\n",
    "\n",
    "if TESTING:\n",
    "    qsysTF, qsysDF = getSysmetricData(G_sysmetric_last_end_time, True)\n",
    "    print(qsysDF.dtypes)\n",
    "    G_sysmetric_last_beg_time = qsysDF['SAMPLE_TIME_BEG'].min()\n",
    "    G_sysmetric_last_end_time = qsysDF['SAMPLE_TIME_END'].max()\n",
    "    print(\"G_sysmetric_last_beg_time\", G_sysmetric_last_beg_time)\n",
    "    print(\"G_sysmetric_last_end_time\", G_sysmetric_last_end_time)\n",
    "    print(qsysTF, qsysDF.shape)\n",
    "    print(qsysDF.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28204b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAshData(minTime_in, maxTime_in, verbose_in):\n",
    "    \n",
    "    minTime = minTime_in.strftime(\"%d-%b-%Y %H:%M:%S\")\n",
    "    maxTime = maxTime_in.strftime(\"%d-%b-%Y %H:%M:%S\")\n",
    "    \n",
    "    if verbose_in:\n",
    "        print(\"\\nENTER Function getAshData, minTime\", minTime, \" maxTime\", maxTime)\n",
    "    \n",
    "    #sql = \"select sample_time, sample_id, session_id, session_state, session_type, wait_class, module from \" \\\n",
    "    sql = \"select sample_id, session_state, session_type, wait_class, module, sql_opcode, pga_allocated, temp_space_allocated from \" \\\n",
    "    + G_par_core[\"ash_object_name\"] \\\n",
    "    + \" where \" + G_par_core[\"ash_where_clause\"] \\\n",
    "    + \"   and sample_time > to_date('\" + minTime + \"','DD-Mon-YYYY HH24:MI:SS')\" \\\n",
    "    + \"   and sample_time < to_date('\" + maxTime + \"','DD-Mon-YYYY HH24:MI:SS')\" \\\n",
    "    + \" order by sample_id, session_id\"\n",
    "        \n",
    "    runSQLTF, DF = runSQL(sql, verbose_in)\n",
    "    \n",
    "    if verbose_in:\n",
    "        print(DF.head())\n",
    "    \n",
    "    if verbose_in:\n",
    "        print(\"\\nEXIT Function getAshData\")\n",
    "    \n",
    "    return runSQLTF, DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d804fb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if TESTING:\n",
    "#    \n",
    "#    qTF, qDF = getAshData(G_sysmetric_last_beg_time, G_sysmetric_last_end_time, True)\n",
    "#    print(qTF, qDF.shape)\n",
    "#    print(qDF.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cb3ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is not completed by any means...\n",
    "\n",
    "def getLabelData(lastSampleDate_in, verbose_in):\n",
    "    \n",
    "    sql = \"select sample_time, sample_id, session_id, sql_id, module from \" \\\n",
    "    + G_par_core[\"label_object_name\"] \\\n",
    "    + \" where \" + G_par_core[\"label_where_clause\"] \\\n",
    "    + \"   and sample_time > to_date('\" + lastSampleDate_in + \"','DD-Mon-YYYY HH24:MI:SS')\" \\\n",
    "    + \" order by sample_id, session_id\"\n",
    "    \n",
    "    runSQLTF, DF = runSQL(sql, verbose_in)\n",
    "    \n",
    "    return runSQLTF, DF\n",
    "\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a65e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNewData(sysDF, ashDF, labelDF, verbose_in):\n",
    "    \n",
    "    # This function will:\n",
    "    #    1. Collect the new SYSMETRIC (sysNewDF) and ASH (ashNewDF) and LABEL (labelNewDF) data,\n",
    "    #    2. Preprocess the just-collected raw SYSMETRIC (sysPP) and ASH (ashPP2) and LABEL (labelPP) data\n",
    "    #    3. Append the preprossed data to the existing SYSMETRIC (sysDF) and ASH (ashDF) \n",
    "    #       and LABEL (labelDF) dataframe\n",
    "    \n",
    "    # Note: Label rows are computed from sysmetric data and not collected from external system\n",
    "    \n",
    "    # Note: Because new sysmetric data is available every \"60\" seconds, but ash data is sampled\n",
    "    #       every second, we use the sysmetric begin and end sample times to then bound what ash data\n",
    "    #       we collect, then collect the ash data.\n",
    "    \n",
    "    if verbose_in:\n",
    "        print(\"\\nENTER Function getNewData\")\n",
    "        print(\"        Gathering SYSMETRIC and ASH data...\")\n",
    "    \n",
    "    resultTF     = False\n",
    "    sysNewRows   = 0\n",
    "    ashNewRows   = 0\n",
    "    labelNewRows = 0\n",
    "    \n",
    "    sysInRows   = sysDF.shape[0]\n",
    "    ashInRows   = ashDF.shape[0]\n",
    "    labelInRows = labelDF.shape[0]\n",
    "\n",
    "    \n",
    "    sysTF, sysNewDF = getSysmetricData(G_sysmetric_last_end_time, verbose_in)\n",
    "    \n",
    "    if verbose_in:\n",
    "        print(sysNewDF.dtypes)\n",
    "    \n",
    "    sysmetric_last_beg_time = sysNewDF['SAMPLE_TIME_BEG'].min()\n",
    "    sysmetric_last_end_time = sysNewDF['SAMPLE_TIME_END'].max()\n",
    "    \n",
    "    diff     = sysmetric_last_end_time - sysmetric_last_beg_time\n",
    "    diff_sec = int(diff.days*24*60*60 + diff.seconds)\n",
    "    \n",
    "    if verbose_in:\n",
    "        print(\"types: beg\", type(sysmetric_last_beg_time), \" end\", type(sysmetric_last_beg_time) )\n",
    "        print(\"times: beg\", sysmetric_last_beg_time, \"end\", sysmetric_last_end_time, \"diff(s)\", diff_sec)\n",
    "    \n",
    "    ashTF, ashNewDF = getAshData(sysmetric_last_beg_time, sysmetric_last_end_time, verbose_in)\n",
    "    \n",
    "    \n",
    "    if ashTF and sysTF:\n",
    "        \n",
    "        sysNewRows = sysNewDF.shape[0]\n",
    "        ashNewRows = ashNewDF.shape[0]\n",
    "        \n",
    "        #\n",
    "        # SYSMETRIC preprocessing\n",
    "        #\n",
    "        if verbose_in:\n",
    "            print(\"\\nPre-Processing SYSMETRIC data...\")\n",
    "        \n",
    "        # Step 1 - Denormalize/Pivot data\n",
    "        \n",
    "        if verbose_in:\n",
    "            print(\"Denormalizing sysNewDF before:\", sysNewDF.shape)\n",
    "            \n",
    "        # The \"values\" will become the new \"columns\" value\n",
    "        sysPP = sysNewDF.pivot_table(index='SAMPLE_TIME_BEG', values='METRIC_VALUE', columns=['METRIC_NAME'])\n",
    "        sysPP.reset_index(inplace=True)\n",
    "        \n",
    "        if verbose_in:\n",
    "            print(\"              sysPP    after:\", sysPP.shape)\n",
    "        \n",
    "        #  Step 4 - Add the collection sequence number\n",
    "        #           Append our new preprocessed sample set with the existing Sysmetric dataframe\n",
    "        #           Ensure all NaN values are set to zero.\n",
    "        sysPP['SEQ_NO'] = G_current_seq_num\n",
    "        sysDF           = sysDF.append(sysPP)\n",
    "        sysDF           = sysDF.fillna(0)\n",
    "        #sysDF.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "        \n",
    "        if verbose_in:\n",
    "            print(\"sysDF.columns\", sysDF.columns)\n",
    "        \n",
    "        \n",
    "        #\n",
    "        # ASH preprocessing\n",
    "        #\n",
    "        if verbose_in:\n",
    "            print(\"\\nPre-Processing ASH data...\")\n",
    "        \n",
    "        # Step 1 - OHE\n",
    "        #          We are prefixing for easier understanding\n",
    "        #          dummy_na=True to ensure we have a kind of \"catch all\" column.\n",
    "        \n",
    "        ashPP = pd.DataFrame(ashNewDF)\n",
    "        ashPP = pd.concat([ashPP, pd.get_dummies(ashPP['SESSION_STATE'], prefix='ash_state', dummy_na=True)], axis=1)\n",
    "        ashPP = pd.concat([ashPP, pd.get_dummies(ashPP['SESSION_TYPE'], prefix='ash_type', dummy_na=True)], axis=1)\n",
    "        ashPP = pd.concat([ashPP, pd.get_dummies(ashPP['WAIT_CLASS'], prefix='ash_wc', dummy_na=True)], axis=1)\n",
    "        ashPP = pd.concat([ashPP, pd.get_dummies(ashPP['MODULE'], prefix='ash_mod', dummy_na=True)], axis=1)\n",
    "        ashPP = pd.concat([ashPP, pd.get_dummies(ashPP['SQL_OPCODE'], prefix='ash_ocode', dummy_na=True)], axis=1)\n",
    "        ashPP = ashPP.drop(columns=['SESSION_STATE','SESSION_TYPE','WAIT_CLASS','MODULE','SQL_OPCODE'])\n",
    "        \n",
    "        #print(\"ashPP.shape\", ashPP.shape)\n",
    "        #print(ashPP.head())\n",
    "        \n",
    "        \n",
    "        # Step 2 - For each ASH column in this sample set, sum all the rows, them divide by the sample time (sec)\n",
    "        #          This will create an average per second standardized value... like AAS\n",
    "        \n",
    "        #          Create the list of all the ASH columns\n",
    "        #          Remove any columns we don't want to keep around\n",
    "        cols = list(ashPP.columns)\n",
    "        cols.remove('SAMPLE_ID')\n",
    "                \n",
    "        #          Do the summing and the average per second math\n",
    "        #          The result will be a list (myList) of each column's average per second\n",
    "        myList = []\n",
    "        \n",
    "        for colName in cols:\n",
    "            theSum       = ashPP[colName].sum()\n",
    "            theAvgPerSec = theSum / diff_sec\n",
    "            \n",
    "            #print(colName, theSum, round(theAvgPerSec,4))\n",
    "            \n",
    "            myList.append(theAvgPerSec)\n",
    "        \n",
    "        \n",
    "        # Step 3 - Create a row dataframe. \n",
    "        #          Columns are the ASH columns, including the OHE data\n",
    "        #          The row data is the average per second values\n",
    "        \n",
    "        # This helped me code adding a list to a dataframe as a single row\n",
    "        #People_List = [['Jon','Smith','Mark','Brown']]\n",
    "        #print(People_List)\n",
    "        #df = pd.DataFrame (People_List,columns=['name1','name2','name3','name4'])\n",
    "        #print(df)\n",
    "        \n",
    "        ashPP2           = pd.DataFrame([myList], columns=[cols])\n",
    "        \n",
    "        #  Step 4 - Add the collection sequence number\n",
    "        #           Append our new preprocessed sample set with the existing ASH dataframe\n",
    "        #           Ensure all NaN values are set to zero.\n",
    "        \n",
    "        ashPP2['SEQ_NO'] = G_current_seq_num\n",
    "        ashDF            = ashDF.append(ashPP2)\n",
    "        ashDF            = ashDF.fillna(0)\n",
    "        #ashDF.reset_index(inplace=True)\n",
    "        \n",
    "        if verbose_in:\n",
    "            print(\"ashDF.columns\",ashDF.columns)\n",
    "            \n",
    "            \n",
    "        #\n",
    "        # LABEL preprocessing\n",
    "        #\n",
    "        # Simply uing sysmetric pre-processsed data (sysPP)\n",
    "        \n",
    "        if verbose_in:\n",
    "            print(\"\\nPre-Processing LABEL data...\")\n",
    "        \n",
    "        labelPP = sysPP.copy()\n",
    "        labelNewRows = labelPP.shape[0]\n",
    "        labelPP['label_value'] = pow(20 * labelPP['Average Active Sessions'] + labelPP['User Calls Per Sec'], 1.34522)/100\n",
    "        columns = ['SEQ_NO', 'label_value']\n",
    "        labelDF = labelDF.append(labelPP[columns])\n",
    "        \n",
    "        if verbose_in:\n",
    "            print(\"labelDF.columns\", labelDF.columns)\n",
    "            print(labelDF)\n",
    "        \n",
    "        \n",
    "        resultTF = True\n",
    "    else:\n",
    "        print(\"Function getNewData problem. ashTF\", ashTF, \" sysTF\", sysTF)\n",
    "    \n",
    "    sysMemory   = sysDF.memory_usage(deep=True).sum()\n",
    "    ashMemory   = ashDF.memory_usage(deep=True).sum()\n",
    "    labelMemory = labelDF.memory_usage(deep=True).sum()\n",
    "    \n",
    "    print(\"In/New/Out/MB.\" + \"  SYS:\" + str(sysInRows) +\"/\"+ str(sysNewRows) +\"/\"+ str(sysDF.shape[0]) +\"/\"+ str(int(sysMemory/1024/1024)) + \\\n",
    "          \"  ASH:\" + str(ashInRows) +\"/\"+ str(ashNewRows) +\"/\"+ str(ashDF.shape[0]) +\"/\"+ str(int(ashMemory/1024/1024)) + \\\n",
    "          \"  LAB:\" + str(labelInRows) +\"/\"+ str(labelNewRows) +\"/\"+ str(labelDF.shape[0]) +\"/\"+ str(int(labelMemory/1024/1024)) )\n",
    "    \n",
    "    if verbose_in:\n",
    "        print(\"\\nEXIT Function getNewData\")\n",
    "    \n",
    "    return resultTF, sysDF, ashDF, labelDF\n",
    "\n",
    "\n",
    "if TESTING:\n",
    "    sDF = pd.DataFrame()\n",
    "    aDF = pd.DataFrame()\n",
    "    lDF = pd.DataFrame()\n",
    "    qTF, sDF, aDF, lDF = getNewData(sDF, aDF, lDF, True)\n",
    "\n",
    "print(\"\\nDone.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee6331a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# MAIN PROGRAM (GLOBAL)\n",
    "\n",
    "G_par_core = readParamFile(False)\n",
    "\n",
    "data_load_on_startup_success = False\n",
    "\n",
    "if str2bool(G_par_core[\"data_load_on_startup\"]):\n",
    "    try:\n",
    "        print(\"Loading startup data\", end=\"...\")\n",
    "\n",
    "        sysFN    = G_par_core[\"sysmetric_filename\"]\n",
    "        ashFN    = G_par_core[\"ash_filename\"]\n",
    "        labelFN  = G_par_core[\"label_filename\"]\n",
    "        latestFN = G_par_core[\"latest_collection_filename\"] # not compressed\n",
    "\n",
    "        sysDF    = pd.read_csv(sysFN, compression='gzip')\n",
    "        ashDF    = pd.read_csv(ashFN, compression='gzip')\n",
    "        labelDF  = pd.read_csv(labelFN, compression='gzip')\n",
    "        latestDF = pd.read_csv(latestFN)\n",
    "\n",
    "        G_current_seq_num         = latestDF['seq_num'][0]\n",
    "\n",
    "        atime_str = latestDF['beg_time'][0]\n",
    "        G_sysmetric_last_beg_time = datetime.strptime(atime_str, '%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        atime = latestDF['end_time'][0]\n",
    "        G_sysmetric_last_end_time = datetime.strptime(atime_str, '%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        data_load_on_startup_success = True\n",
    "        \n",
    "        print(\"done.\")\n",
    "    \n",
    "    except BaseException as e:\n",
    "        print(\"failed:\", e)\n",
    "\n",
    "if not data_load_on_startup_success:\n",
    "    \n",
    "    print(\"NOT loading startup data. Resetting.\\n\")\n",
    "    sysDF   = pd.DataFrame()\n",
    "    ashDF   = pd.DataFrame()\n",
    "    labelDF = pd.DataFrame()\n",
    "    \n",
    "    G_current_seq_num = 0\n",
    "    G_sysmetric_last_beg_time = datetime.now() - timedelta(days=10)\n",
    "    G_sysmetric_last_end_time = datetime.now() - timedelta(days=10)\n",
    "\n",
    "print(\"G_current_seq_num        \", G_current_seq_num)\n",
    "print(\"G_sysmetric_last_beg_time\", G_sysmetric_last_beg_time)\n",
    "print(\"G_sysmetric_last_end_time\", G_sysmetric_last_end_time)\n",
    "print()\n",
    "\n",
    "while True:\n",
    "    G_par_core = readParamFile(False) # resetting G_par_core... only place reset\n",
    "    \n",
    "    mainVerbose = str2bool(G_par_core[\"debug_detail_enable\"])\n",
    "        \n",
    "    newDataAvailable, newBegDate, newEndDate = IsNewDataAvailable(mainVerbose)\n",
    "    \n",
    "    if newDataAvailable:\n",
    "        G_current_seq_num = G_current_seq_num + 1\n",
    "        print(datetime.now().strftime(\"%d-%b-%Y %H:%M:%S\"), \"New data begin/end time\", newBegDate.strftime(\"%d-%b-%Y %H:%M:%S\"), \"/\", newEndDate.strftime(\"%d-%b-%Y %H:%M:%S\"), G_current_seq_num)\n",
    "        allOK, sysDF, ashDF, labelDF = getNewData(sysDF, ashDF, labelDF, mainVerbose) # mainVerbose)\n",
    "        G_sysmetric_last_beg_time = newBegDate\n",
    "        G_sysmetric_last_end_time = newEndDate\n",
    "        \n",
    "        print(\"Committing\", end=\"...\")\n",
    "        tic = time.perf_counter()\n",
    "        \n",
    "        latestData = [[G_current_seq_num, G_sysmetric_last_beg_time, G_sysmetric_last_end_time]]\n",
    "        #print(\"latestData\", latestData)\n",
    "        latestDF   = pd.DataFrame(latestData, columns=['seq_num', 'beg_time', 'end_time'])\n",
    "        \n",
    "        sysFN    = G_par_core[\"sysmetric_filename\"]\n",
    "        ashFN    = G_par_core[\"ash_filename\"]\n",
    "        labelFN  = G_par_core[\"label_filename\"]\n",
    "        latestFN = G_par_core[\"latest_collection_filename\"] # not compressed\n",
    "        \n",
    "        sysDF.to_csv(   sysFN,   header=True, index=False, compression='gzip')\n",
    "        ashDF.to_csv(   ashFN,   header=True, index=False, compression='gzip')\n",
    "        labelDF.to_csv( labelFN, header=True, index=False, compression='gzip')\n",
    "\n",
    "        latestDF.to_csv(latestFN, header=True, index=False)\n",
    "        \n",
    "        toc = time.perf_counter()\n",
    "        print(f\"completed in {toc - tic:0.2f}s.\")\n",
    "        \n",
    "    else:\n",
    "         print(datetime.now().strftime(\"%d-%b-%Y %H:%M:%S\"), \"No new data.\")\n",
    "    \n",
    "    if mainVerbose:\n",
    "        print(\"\\nSleeping...\\n\")\n",
    "    \n",
    "    time.sleep(int(G_par_core[\"sample_frequency_sec\"]))\n",
    "\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
